{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09fc3401",
   "metadata": {},
   "source": [
    "# Business problem: \n",
    " \n",
    "‘ABC’ bank operates in several countries.The bank is facing revenue loss because of customer churn. Hence they intend to design and launch a special incentives and rewards program to help retain customers of the country with highest churn, hence reducing overall revenue losses.\n",
    "\n",
    "The bank also wants to be able to predict which customers are going to churn so that some standard set of actions can be implemented to retain customers.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a651ad1a",
   "metadata": {},
   "source": [
    "# Project objectives:\n",
    "\n",
    "1. To determine country with the highest churn \n",
    "2. To identify the characteristics of churned customers in this country by employing several visualizations \n",
    "3. To build an ML model which predicts a customer’s propensity to churn based on various features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bfd0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbab6a9b",
   "metadata": {},
   "source": [
    "# reading the Bank.csv dataset\n",
    "f1 = pd.read_csv(\"Bank.csv\")\n",
    "f1.head(10)\n",
    "print(f1.info())\n",
    "#the 'Bank.csv'dataset contains 10,000 rows and 12 columns \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60af3329",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_36524\\3793733706.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'f1' is not defined"
     ]
    }
   ],
   "source": [
    "f1.describe(include ='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90080f7d",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f40295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking number of missing values in each column of the dataset\n",
    "f1.isnull().sum() \n",
    "\n",
    "#The dataset appears to have 84 null values in age column  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4015a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the mean value of age\n",
    "age_mean = f1.age.mean()\n",
    "\n",
    "#replacing null values in 'age' with mean values in age: \n",
    "f1.age.fillna(age_mean, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7dfbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rechecking if dataset has null values after null value treatment\n",
    "f1.isnull().sum()\n",
    "print(f1)\n",
    "\n",
    "#dropping columns which are unnecessary for exploration\n",
    "f11 = f1.drop('customer_id', axis=1)\n",
    "\n",
    "#converting float type numerical variables to int type\n",
    "f2 = f11.copy()\n",
    "f2['balance'] = f2['balance'].astype(int)\n",
    "f2['estimated_salary'] = f2['estimated_salary'].astype(int)\n",
    "f2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fb2caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating categorical variables, one each to for numeric variables- age, tenure and balance, estimated salary and credit score.\n",
    "#created these variables for making easy to understand visualisations \n",
    "age_bins = [0, 20, 30, 40, 50, 60, 70, 80, 100]\n",
    "tenure_bins = [0, 2, 4, 6, 8, 10]\n",
    "balance_bins = [0, 50000, 100000, 150000, 200000, 250000, 300000]\n",
    "salary_bins = [0, 50000, 100000, 150000, 200000]\n",
    "age_labels = ['<20', '20-30', '30-40', '40-50', '50-60', '60-70', '70-80', '80+']\n",
    "tenure_labels = ['0-2', '2-4', '4-6', '6-8', '8-10']\n",
    "balance_labels = ['<$50k', '$50k-100k', '$100k-150k', '$150k-200k', '$200k-250k', '>$250K']\n",
    "salary_labels = ['<$50K', '$50K-$100K', '$100K-$150K', '>$150K']\n",
    "credit_bins = [300, 579, 669, 739, 799, 850]\n",
    "credit_labels = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent']\n",
    "\n",
    "f2['credit_score_range'] = pd.cut(f2['credit_score'], bins= credit_bins, labels= credit_labels, include_lowest= True)\n",
    "f2['age_range'] = pd.cut(f2['age'], bins= age_bins, labels= age_labels)\n",
    "f2['tenure_range'] = pd.cut(f2['tenure'], bins= tenure_bins, labels= tenure_labels, include_lowest= True)\n",
    "f2['balance_range'] = pd.cut(f2['balance'], bins= balance_bins, labels= balance_labels, include_lowest= True)\n",
    "f2['salary_range'] = pd.cut(f2['estimated_salary'], bins= salary_bins, labels= salary_labels)\n",
    "f2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93738f34",
   "metadata": {},
   "source": [
    "# Basic Exploratory Data Analysis to understand distribution of features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Distribution of numeric features\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "f2.hist(figsize=(14,14))\n",
    "\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa68f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of categorical features \n",
    "\n",
    "# Bar plot for \"Gender\"\n",
    "plt.figure(figsize=(4,4))\n",
    "f2['gender'].value_counts().plot.bar(color=['b', 'r'])\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Gender')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942e8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot for \"country\"\n",
    "plt.figure(figsize=(6,4))\n",
    "f2['country'].value_counts().plot.bar(color=['b', 'g', 'r'])\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Geography')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432640e3",
   "metadata": {},
   "source": [
    "## Insights from basic distribution analysis \n",
    "\n",
    "### There are high number of customers with :\n",
    "\n",
    "1. credit score between 650 to 700\n",
    "2. age between 30-40\n",
    "3. tenure of 9-10 years\n",
    "4. have a balance of O\n",
    "5. have purchased only 1 product from the bank\n",
    "6. have a credit card from the bank\n",
    "7. have an active account i.e they have made atleast one transactions in the last month\n",
    "\n",
    "- Approximately 20% of total customers have churned \n",
    "\n",
    "- France has the higest number of customers\n",
    "\n",
    "- The customer base has more females than males \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6058ab",
   "metadata": {},
   "source": [
    "## EDA to understand distrirbution of churned customers \n",
    "\n",
    "- 20% of all the bank's customers have exited. We look at what is the distribution of these customers for variables categorical variables 'country' and 'gender' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a598ad2",
   "metadata": {},
   "source": [
    "### 1. Which country has most number of customers who have churned? \n",
    "- Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb655c54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropping all rows containing retained customer's info\n",
    "f8 = f2.copy()\n",
    "f8.drop(f8[f8['churn'] == 0].index, inplace = True)\n",
    "s3 = px.pie(f8, values='churn', names='country', title='Churn by Country')\n",
    "s3.update_traces(textposition='inside', textinfo='percent+label')\n",
    "s3.show()\n",
    "\n",
    "#Hence, The number of customers who exited the bank was highest in Germany\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43794655",
   "metadata": {},
   "source": [
    "### Who churn more? Men or women?\n",
    "- More Female customers have churned as compared to male customers in all three countries \n",
    "\n",
    "  Additional information from graph:\n",
    "  - Though Germany has highest churn% it has fewer number of churned female customers than France.\n",
    "  - Germany has the highest number of churned male customers overall \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b67b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa3=f8.copy()\n",
    "aa3 = aa3[aa3['churn'] == 1]\n",
    "\n",
    "# group the data by gender and country\n",
    "gender_country = aa3.groupby(['gender', 'country']).size().reset_index(name='Count')\n",
    "male_counts = gender_country[gender_country['gender'] == 'Male']['Count'].tolist()\n",
    "female_counts = gender_country[gender_country['gender'] == 'Female']['Count'].tolist()\n",
    "countries = sorted(set(gender_country['country']))\n",
    "\n",
    "# create the bar chart\n",
    "bar_width = 0.35\n",
    "x = np.arange(len(countries))\n",
    "fig, ax = plt.subplots()\n",
    "male_bars = ax.bar(x - bar_width/2, male_counts, bar_width, label='Male')\n",
    "female_bars = ax.bar(x + bar_width/2, female_counts, bar_width, label='Female')\n",
    "\n",
    "# add labels and legend\n",
    "ax.set_xlabel('Country')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Churned count by Gender and Country')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(countries)\n",
    "ax.legend()\n",
    "\n",
    "# add data labels\n",
    "for bar in male_bars + female_bars:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate('{}'.format(height), xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom')\n",
    "                \n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e1db1",
   "metadata": {},
   "source": [
    "### German customers in which age range and FICO credit score category churned the most?\n",
    "\n",
    "- Age 40-50\n",
    "- Credit score: Fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8359574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "f9 = f8.copy()#dataframe used for Question 3 \n",
    "# Filtering the data to only include customers who churned in Germany\n",
    "f9.drop(f9[f9['country'] != 'Germany'].index, inplace = True)\n",
    "\n",
    "#Grouping the data by a categorical variable\n",
    "grouped = f9.groupby(['age_range', 'credit_score_range']).size().reset_index(name='count')\n",
    "\n",
    "#Pivoting the data to create a matrix of counts\n",
    "pivoted = grouped.pivot(index='age_range', columns='credit_score_range', values='count')\n",
    "\n",
    "#Creating a stacked bar chart\n",
    "data = []\n",
    "for col in pivoted.columns:\n",
    "    trace = go.Bar(x=pivoted.index, y=pivoted[col], name=col)\n",
    "    data.append(trace)\n",
    "\n",
    "layout = go.Layout(title='Customer Churn in Germany by age and FICO credit score ',\n",
    "                   xaxis=dict(title='Age Group'),\n",
    "                   yaxis=dict(title='Count'),\n",
    "                   barmode='stack',\n",
    "                   legend=dict(title='FICO credit score'))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "pio.show(fig)\n",
    "\n",
    "#Most customers in Germany who exited the bank belonged to the 40-50 age group and they had a 'Fair' FICO credit score \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f858636d",
   "metadata": {},
   "source": [
    "### What is most common salary range of Churned customers in germany?\n",
    "- most customers within this goup has a salary <$50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015b6941",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa2 =f9.copy() \n",
    "\n",
    "# replace 0 with 'Retained' and 1 with 'Churned'\n",
    "aa2['churn'] = aa2['churn'].replace({0: 'Retained', 1: 'Churned'})\n",
    "\n",
    "# counting occurrences of churn\n",
    "##dropping rows of retained customers\n",
    "aa2.drop(aa2[aa2['churn'] ==0].index, inplace = True)\n",
    "salary_counts = aa2['salary_range'].value_counts()\n",
    "plt.pie(salary_counts, labels= salary_counts.index, autopct='%1.1f%%')\n",
    "plt.legend(title=\"Salary_Range\", loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "plt.title('Churn Proportion by Salary Range')\n",
    "plt.show()\n",
    "\n",
    "#interpretation: less than 50k are most likely to churn "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0107b02",
   "metadata": {},
   "source": [
    "### What is the balance range of German churned customers\n",
    "\n",
    "-   most churned german customers have an account balance of $ 100k-150k in their accounts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d274709",
   "metadata": {},
   "outputs": [],
   "source": [
    "s10 =f9.copy() \n",
    "balance_count1 = s10.groupby(['balance_range']).size().reset_index(name='count')\n",
    "print(balance_count1)\n",
    "#there are no chured customers with account balance <$50k, $200-250k, $>250k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5234ec36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a bar representation to visualze the above result \n",
    "excluded_ranges = ['<$50k', '$200k-250k', '>$250K']\n",
    "balance_count1= balance_count1[~balance_count1['balance_range'].isin(excluded_ranges)]\n",
    "\n",
    "# create an interactive bar chart using plotly.express\n",
    "fig18 = px.bar(balance_count1, x='balance_range', y='count', \n",
    "               title='Count of Churned German Customers in each Account Balance Range',\n",
    "               labels={'balance_range': 'Balance Range', 'count': 'Count'},\n",
    "               color_discrete_sequence=['#636EFA'])\n",
    "\n",
    "# remove the legend\n",
    "fig18.update_layout(showlegend=False)\n",
    "\n",
    "fig18.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749bfd1",
   "metadata": {},
   "source": [
    "### What is the tenure and activity status of most German customers churned ?\n",
    "\n",
    "Most customers in this group had a tenure between 0-2 years and were inactive members \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d27428",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa4 = f9.copy()\n",
    "\n",
    "tenure_distribution = aa4.groupby(['tenure_range','active_member']).size()\n",
    "# Unstack the series by active_member level\n",
    "pivoted = tenure_distribution.unstack(level=-1)\n",
    "\n",
    "# Creating a stacked bar chart\n",
    "data1 = []\n",
    "for col in pivoted.columns:\n",
    "    trace1 = go.Bar(x=pivoted.index, y=pivoted[col], name=col)\n",
    "    data1.append(trace1)\n",
    "\n",
    "layout1 = go.Layout(title='Customer Churn by tenure and activity status in Germany',\n",
    "                   xaxis=dict(title='Tenure Age'),\n",
    "                   yaxis=dict(title='Count'),\n",
    "                   barmode='stack',\n",
    "                   legend=dict(title='Active Member'))\n",
    "\n",
    "fig20 = go.Figure(data=data1, layout=layout1)\n",
    "pio.show(fig20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb75896",
   "metadata": {},
   "source": [
    "# Conclusion of EDA:\n",
    "\n",
    "After analyzing the churn rate of customers from different countries, we found that Germany has the highest overall churn rate. Further analysis revealed that female customers in Germany have a higher churn rate compared to male customers.\n",
    "\n",
    "Moreover , we observed that customers who earn less than $50k in Germany have the highest proportion of churned customers. \n",
    "\n",
    "Additionally, most of the churned customers in Germany are between the age group of 40-50 years with a Fair FICO credit score.\n",
    "\n",
    "Most churned German customers had an account balance in between $100K-150K\n",
    "\n",
    "Most churned German customers had been with the bank for <=2 years and were inactive \n",
    "\n",
    "\n",
    "Therefore , our analysis suggests that the bank should keep in mind these characteristics of churned customers in germany to create an incentive/ rewards program which will help gain thier loyalty, thereby reducing churn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78acf5-c6a2-42b4-bb82-f16b3a6d4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "f11.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f4891-0ce3-45ea-9687-21512fb8b762",
   "metadata": {},
   "source": [
    "## Data Preparation  for Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9627904-e51e-4328-9f28-ab091a8b39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, confusion_matrix, classification_report\n",
    "\n",
    "# assume X_train and X_test are the training and testing feature dataframes\n",
    "# and y_train and y_test are the corresponding target series\n",
    "# assume num_cols and cat_cols are the lists of column names of numerical and categorical features, respectively\n",
    "\n",
    "num_cols1= ['age', 'credit_score','tenure', 'balance','products_number', 'credit_card', 'active_member', 'estimated_salary']   # features / independent variables \n",
    "cat_cols1 = ['country', 'gender']\n",
    "target = ['churn']     # target / dependent variable \n",
    "\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder()\n",
    "\n",
    "# combine the transformers using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols1),\n",
    "        ('cat', cat_transformer, cat_cols1)])\n",
    "\n",
    "# apply the preprocessor to the dataframe\n",
    "X = preprocessor.fit_transform(f11)\n",
    "Y = f11['churn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce1f71e-e82d-4de7-a050-a6b3f9cfabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a7e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5fb6ef-982c-47d7-9ae3-b17564de91d3",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b915c178-113f-4f9b-8776-2b6892226a70",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfe5233-c50a-4660-9a33-b7ac43b3e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate     # import cross_validation function from sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier    # import KNN classifer \n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "## fit with 5 folder cross validation \n",
    "\n",
    "scores = cross_validate(estimator=knn, X=X, y=Y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Average Fitting Time:\", scores['fit_time'].mean())\n",
    "print(\"Average Accuracy:\", scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc439a-0239-443f-8e7c-0e344564065b",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134767f9-5e85-46e5-a2e4-d3579379bc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "scores = cross_validate(estimator=lr, X=X, y=Y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Average Fitting Time:\", scores['fit_time'].mean())\n",
    "print(\"Average Accuracy:\", scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588b6187-5073-486a-8736-7cb12e46e0be",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58076741-7cd5-4c2f-8383-6a7c6acb0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC()\n",
    "\n",
    "scores = cross_validate(estimator=svm, X=X, y=Y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Average Fitting Time:\", scores['fit_time'].mean())\n",
    "print(\"Average Accuracy:\", scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ac82ac-1a42-4a64-9ab6-140c7fd36629",
   "metadata": {},
   "source": [
    "### Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c472a5f-bdbd-44ff-926b-c987c11f20c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "\n",
    "scores = cross_validate(estimator=nb, X=X, y=Y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Average Fitting Time:\", scores['fit_time'].mean())\n",
    "print(\"Average Accuracy:\", scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730fea53-e7ec-4457-91ab-fffe13a2b536",
   "metadata": {},
   "source": [
    "### Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1254eb29-7baa-4681-8951-31c325c55deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_validate(estimator=tree, X=X, y=Y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Average Fitting Time:\", scores['fit_time'].mean())\n",
    "print(\"Average Accuracy:\", scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5f550-2b7b-4959-ab6c-b63d330d87e4",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44985bcb-4bdd-45d6-bfa6-0d4860220b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "scores = cross_validate(estimator=rf, X=X, y=Y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Average Fitting Time:\", scores['fit_time'].mean())\n",
    "print(\"Average Accuracy:\", scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6cb1a5-65be-4c34-8c0a-163ec3b9286b",
   "metadata": {},
   "source": [
    "### Gradient Boost Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460f9d84-5562-4c20-9715-c587dc9bbac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "scores = cross_validate(estimator=gb, X=X, y=Y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Average Fitting Time:\", scores['fit_time'].mean())\n",
    "print(\"Average Accuracy:\", scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffbebaf-6d56-4723-852e-26b276acb130",
   "metadata": {},
   "source": [
    "## Model Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d953c2cf-7ff1-4505-89da-3c1dc3e7ed94",
   "metadata": {},
   "source": [
    "### We write a loop to search for the best model for the problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3964d7-78c8-4b0d-9e8b-b9df28ad42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## candidate models \n",
    "knn = KNeighborsClassifier()\n",
    "lr = LogisticRegression()\n",
    "svm = SVC()\n",
    "nb = GaussianNB()\n",
    "tree = DecisionTreeClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "models = {\"KNN\": knn, \"LogisticRegression\": lr, \"SVM\": svm, \n",
    "          \"Naive Bayes\": nb, \"DecisionTree\": tree, \"RandomForest\": rf}\n",
    "results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    default = {\"Model\":model_name, \"Fitting Time\": np.nan, \"Accuracy\": np.nan}\n",
    "    scores = cross_validate(estimator=model, X=X, y=Y, cv=5, scoring=\"accuracy\")\n",
    "    default['Fitting Time'] = scores['fit_time'].mean()\n",
    "    default['Accuracy'] = scores['test_score'].mean()\n",
    "    results.append(default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfea81a-1b63-4220-9eb9-13c2da274962",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(results)\n",
    "results.sort_values(\"Accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e5fd0-1b05-48ac-93a9-2cff9cda7362",
   "metadata": {},
   "outputs": [],
   "source": [
    "### visualize the prediction \n",
    "\n",
    "ax = sns.scatterplot(x=\"Fitting Time\", y=\"Accuracy\", data=results)\n",
    "for x, y, model_name in results[['Fitting Time', 'Accuracy', 'Model']].values:\n",
    "    ax.text(x+.005, y, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39ec80-2637-4971-a37c-247e5f4c72c0",
   "metadata": {},
   "source": [
    "As we can see, the best model is the Random Forest model. We can either choose \n",
    "1. fine tune the best model to get the best prediction result. \n",
    "2. use a set of best model to generate an ensemble model for prediction. \n",
    "\n",
    "We have chosen to fine tune the best model i.e Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb1e30e-27ee-4d79-8eea-ac9252fdee26",
   "metadata": {},
   "source": [
    "### Next Step 1: Fine Tune the Best Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d14e5be-621a-4e33-a1fe-a0bd64af117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV    ## use cross validation to search for best model hyper-parameters \n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 15],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'class_weight':[None, \"balanced_subsample\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec0af2-4d36-4faa-bf95-969f5e810fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "grid_search = GridSearchCV(rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X, Y)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3ecd6e",
   "metadata": {},
   "source": [
    "# Precision, recall and F1 scores: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eacf87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing metrics\n",
    "roc_auc_score(Y_test, rf.predict(X_test))\n",
    "recall_score(Y_test, rf.predict(X_test))\n",
    "confusion_matrix(Y_test, rf.predict(X_test))\n",
    "print(classification_report(Y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f756f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff79bd74-12c6-4e20-a978-2cbc4b2a7f9c",
   "metadata": {},
   "source": [
    "- As we can see, the fine tuned RF model is 0.004 higher in accuracy than the RF model with default parameters. \n",
    "- The model is able to predict the customers that will churn with ~86% accuracy "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
